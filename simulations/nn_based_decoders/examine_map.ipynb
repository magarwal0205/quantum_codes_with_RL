{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_data(savefile_bool, p_x, p_y, p_z, tot_samples):\n",
    "\n",
    "    syndrome_col = np.zeros([tot_samples, n-k])\n",
    "    error_col = np.zeros([tot_samples, 2*n])\n",
    "\n",
    "    for i_sample in range(tot_samples):\n",
    "        # generate qbits randomly\n",
    "        tx_qbits = np.random.rand(2**k)\n",
    "        tx_qbits = NormalizeState(tx_qbits)\n",
    "\n",
    "        # encode qbits\n",
    "        tx_encoded = encode_qbits(tx_qbits)\n",
    "\n",
    "        # channel\n",
    "        rx_erry, error_vector = depolarizing_channel(tx_encoded, p_x, p_y, p_z)\n",
    "\n",
    "        # syndrome\n",
    "        syndr = get_syndrome(rx_erry)\n",
    "\n",
    "        # fill columns\n",
    "        syndrome_col[i_sample, :] = syndr\n",
    "        error_col[i_sample, :] = error_vector\n",
    "        \n",
    "        if(savefile_bool):\n",
    "            savefile_name = 'data_' + str(n) + ',' + str(k) + '_tot_samples_'+ str(tot_samples) + '_p_' + str(p_x)\n",
    "            savefile_name_syndr = savefile_name + '_syndr.csv'\n",
    "            savefile_name_error = savefile_name + '_error.csv'\n",
    "\n",
    "            np.savetxt(savefile_name_syndr, syndrome_col, delimiter=\",\")\n",
    "            np.savetxt(savefile_name_error, error_col, delimiter=\",\")\n",
    "\n",
    "            print('Saved files:')\n",
    "            print(savefile_name_syndr)\n",
    "            print(savefile_name_error)\n",
    "        \n",
    "    return syndrome_col, error_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = np.eye(2)\n",
    "X = np.array([[0.0, 1.0],[1.0, 0.0]])\n",
    "Z = np.array([[1.0, 0.0],[0.0, -1.0]])\n",
    "Y = np.matmul(X,Z)\n",
    "\n",
    "zero = np.array([[1.0], [0.0]]) # |0>\n",
    "one = np.array([[0.0], [1.0]]) # |1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeState(ipVal):\n",
    "    if(sp.linalg.norm(ipVal) == 0): return ipVal\n",
    "    else : return ipVal / sp.linalg.norm(ipVal)\n",
    "    \n",
    "def NKron(*args):\n",
    "  result = np.array([[1.0]])\n",
    "  for op in args:\n",
    "    result = np.kron(result, op)\n",
    "  return result\n",
    "    \n",
    "def NKronModified(checkRowMod):\n",
    "  result = np.array([[1.0]])\n",
    "  for ind in checkRowMod:\n",
    "    if(ind == 0):\n",
    "        op = Id\n",
    "    elif(ind == 1):\n",
    "        op = X\n",
    "    elif(ind == 2):\n",
    "        op = Y\n",
    "    elif(ind == 3):\n",
    "        op = Z\n",
    "    result = np.kron(result, op)\n",
    "  return result\n",
    "\n",
    "def getGenerator(checkRow):\n",
    "    checkRowModified = np.zeros(n, dtype=int)\n",
    "    \n",
    "    checkRowModified[(checkRow[:n] == checkRow[n:]) & (checkRow[n:] == 1)] = 2\n",
    "    checkRowModified[(checkRow[:n] == 1) & (checkRowModified != 2)] = 1\n",
    "    checkRowModified[(checkRow[n:] == 1) & (checkRowModified != 2)] = 3\n",
    "    \n",
    "    return NKronModified(checkRowModified)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkMatrix = np.array([[0,0,0,1,1,1,1, 0,0,0,0,0,0,0],\n",
    "#                         [0,1,1,0,0,1,1, 0,0,0,0,0,0,0],\n",
    "#                         [1,0,1,0,1,0,1, 0,0,0,0,0,0,0],\n",
    "#                         [0,0,0,0,0,0,0, 0,0,0,1,1,1,1],\n",
    "#                         [0,0,0,0,0,0,0, 0,1,1,0,0,1,1],\n",
    "#                         [0,0,0,0,0,0,0, 1,0,1,0,1,0,1]])\n",
    "\n",
    "checkMatrix = np.array([[1,0,0,1,0, 0,1,1,0,0],\n",
    "                        [0,1,0,0,1, 0,0,1,1,0],\n",
    "                        [1,0,1,0,0, 0,0,0,1,1],\n",
    "                        [0,1,0,1,0, 1,0,0,0,1]])\n",
    "\n",
    "n = int(checkMatrix.shape[1]/2)\n",
    "k = n-checkMatrix.shape[0]\n",
    "\n",
    "gi = np.zeros([n-k, 2**n, 2**n])\n",
    "for i in range(n-k):\n",
    "    gi[i,:,:] = getGenerator(checkMatrix[i,:])\n",
    "\n",
    "########## G Matrix ##########\n",
    "Gmatrix = np.eye(gi[0,:,:].shape[0], gi[0,:,:].shape[1]) # generator matrix corresponding to this code\n",
    "for i in range(n-k):\n",
    "    Gmatrix = Gmatrix + np.matmul(gi[i,:,:], Gmatrix)\n",
    "Gmatrix = np.round(Gmatrix)\n",
    "\n",
    "########## Non-zero unique columns ##########\n",
    "# get boolean array if the columns are zero or not\n",
    "zeroCols = np.zeros(Gmatrix.shape[1])\n",
    "for i in range(Gmatrix.shape[1]):\n",
    "    zeroCols[i] = all(Gmatrix[:,i] == np.zeros(Gmatrix.shape[0]))\n",
    "\n",
    "# get indices of non-zero columns\n",
    "nonZeroColsList = np.argwhere(zeroCols==0).flatten()\n",
    "\n",
    "# get all non zero columns\n",
    "GmatrixNonZero = np.zeros([Gmatrix.shape[0], nonZeroColsList.shape[0]])\n",
    "i = 0\n",
    "for ind in nonZeroColsList:\n",
    "    GmatrixNonZero[:,i] = Gmatrix[:,ind]\n",
    "    i = i+1\n",
    "\n",
    "# get all non zero and unique columns and there indices\n",
    "GmatrixNonZeroUniqueInd, nonZeroUniqueInd = np.unique(GmatrixNonZero, axis = 1, return_index=True)\n",
    "nonZeroUniqueInd = nonZeroColsList[nonZeroUniqueInd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_qbits(qbits):\n",
    "    # get extended qbits corresponding to non-zero column indices of G matrix\n",
    "    encoded = np.zeros(2**n)\n",
    "    i = 0\n",
    "    for nonZeroIndex in np.sort(nonZeroUniqueInd):\n",
    "        if(i>=2**k):\n",
    "            break\n",
    "        encoded[nonZeroIndex] = qbits[i]\n",
    "        i = i+1\n",
    "    encoded = NormalizeState(encoded)\n",
    "\n",
    "    # encode transmit qbits using generators\n",
    "    for i in range(n-k):\n",
    "        encoded = encoded + np.matmul(gi[i,:,:], encoded)\n",
    "    encoded = NormalizeState(encoded)\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "def depolarizing_channel(input_qbits, p_x, p_y, p_z):\n",
    "    p_channel = p_channel = [1-p_x-p_y-p_z, p_x, p_y, p_z]  \n",
    "    errMatrix = np.random.multinomial(1, p_channel, size=n)\n",
    "    error_vector = errMatrix@np.array([0,1,2,3])\n",
    "    channel_error = NKronModified(error_vector)\n",
    "    \n",
    "    output_qbits = np.dot(channel_error, input_qbits)\n",
    "    \n",
    "    error_vector = np.append(error_vector.reshape([n,1]), np.zeros([n,1]), axis=1)\n",
    "    \n",
    "    error_vector[error_vector[:,0] == 1, 1] = 1\n",
    "    error_vector[error_vector[:,0] == 3, 1] = 1\n",
    "    error_vector[error_vector[:,0] == 1, 0] = 0\n",
    "    error_vector[error_vector[:,0] == 2, 0] = 1\n",
    "    error_vector[error_vector[:,0] == 3, 0] = 1\n",
    "    \n",
    "    return output_qbits, error_vector.flatten()\n",
    "\n",
    "def get_syndrome(input_qbits):\n",
    "    syndr = np.zeros(n-k)\n",
    "    for i in range(n-k):\n",
    "        syndr[i] = np.dot(input_qbits.transpose(), np.dot(gi[i,:,:], input_qbits))\n",
    "    syndr = syndr.flatten() \n",
    "    \n",
    "    syndr[syndr>0] = 0\n",
    "    syndr[syndr<0] = 1    \n",
    "    \n",
    "    return syndr\n",
    "\n",
    "def generate_data(savefile_bool, p_x, p_y, p_z, tot_samples):\n",
    "\n",
    "    syndrome_col = np.zeros([tot_samples, n-k])\n",
    "    error_col = np.zeros([tot_samples, 2*n])\n",
    "\n",
    "    for i_sample in range(tot_samples):\n",
    "        # generate qbits randomly\n",
    "        tx_qbits = np.random.rand(2**k)\n",
    "        tx_qbits = NormalizeState(tx_qbits)\n",
    "\n",
    "        # encode qbits\n",
    "        tx_encoded = encode_qbits(tx_qbits)\n",
    "\n",
    "        # channel\n",
    "        rx_erry, error_vector = depolarizing_channel(tx_encoded, p_x, p_y, p_z)\n",
    "\n",
    "        # syndrome\n",
    "        syndr = get_syndrome(rx_erry)\n",
    "\n",
    "        # fill columns\n",
    "        syndrome_col[i_sample, :] = syndr\n",
    "        error_col[i_sample, :] = error_vector\n",
    "        \n",
    "        if(savefile_bool):\n",
    "            savefile_name = 'data_' + str(n) + ',' + str(k) + '_tot_samples_'+ str(tot_samples) + '_p_' + str(p_x)\n",
    "            savefile_name_syndr = savefile_name + '_syndr.csv'\n",
    "            savefile_name_error = savefile_name + '_error.csv'\n",
    "\n",
    "            np.savetxt(savefile_name_syndr, syndrome_col, delimiter=\",\")\n",
    "            np.savetxt(savefile_name_error, error_col, delimiter=\",\")\n",
    "\n",
    "            print('Saved files:')\n",
    "            print(savefile_name_syndr)\n",
    "            print(savefile_name_error)\n",
    "        \n",
    "    return syndrome_col, error_col\n",
    "\n",
    "def build_decoder(tot_layers, hidden_dim, hidden_actvn, output_actvn, loss_func, optimizer, metrics):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hidden_dim, activation=hidden_actvn, input_shape=(n-k,), name = 'layer_0'))\n",
    "    for layers in range(tot_layers-1):\n",
    "        model.add(Dense(hidden_dim, activation=hidden_actvn, name = 'layer_' + str(layers+1)))\n",
    "        model.add(BatchNormalization(name='normalize_'+str(layers+1), trainable=True))\n",
    "    model.add(Dense(2*n, activation=output_actvn, name = 'output_layer'))\n",
    "    \n",
    "    model.compile(loss=loss_func, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(p_x, p_y, p_z, tot_samples, tot_layers, hidden_dim, hidden_actvn, output_actvn, loss_func, optimizer, metrics, verbose_bool, tot_epochs):\n",
    "    syndromes, errors = generate_data(False, p_x, p_y, p_z, tot_samples)\n",
    "    X_train = syndromes\n",
    "    y_train = errors\n",
    "\n",
    "    # process data for argmax P(e/s)\n",
    "\n",
    "    X_train_unique = np.unique(X_train, axis=0)\n",
    "    y_train_unique = np.zeros([X_train_unique.shape[0], y_train.shape[1]])\n",
    "\n",
    "    temp_ind = 0\n",
    "    for train_sample in X_train_unique:\n",
    "        temp_error_list = y_train[np.all(X_train == train_sample, axis=1)]  \n",
    "        temp_error_list_unique, counts = np.unique(temp_error_list, axis=0, return_counts=True)\n",
    "        y_train_unique[temp_ind] = temp_error_list_unique[counts == max(counts)][0,:].flatten()\n",
    "        temp_ind = temp_ind + 1\n",
    "\n",
    "    model = build_decoder(tot_layers, hidden_dim, hidden_actvn, output_actvn, loss_func, optimizer, metrics)\n",
    "    model.fit(X_train_unique, y_train_unique, epochs=500, verbose=verbose_bool)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_iter = 1000\n",
    "tot_iter_algo = 10\n",
    "\n",
    "tot_probabs = 25\n",
    "max_probab = 1-0.01-0.01\n",
    "# p_y = a_y*p_x + b_y\n",
    "a_y = 0\n",
    "b_y = 0\n",
    "# p_z = a_z*p_x + b_z\n",
    "a_z = 0\n",
    "b_z = 0\n",
    "\n",
    "# train model parameters\n",
    "tot_samples = 10000\n",
    "\n",
    "tot_layers=5\n",
    "hidden_dim=100\n",
    "hidden_actvn='relu'\n",
    "output_actvn='sigmoid'\n",
    "learning_rate = 0.01\n",
    "tot_epochs = 500\n",
    "\n",
    "# optimizer = Adam(learning_rate)\n",
    "loss_func='binary_crossentropy' # binary_crossentropy # mean_squared_error\n",
    "metrics=['binary_crossentropy', 'acc']\n",
    "verbose_bool = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x = 0.1\n",
    "p_y = a_y*p_x + b_y\n",
    "p_z = a_z*p_x + b_z\n",
    "\n",
    "syndromes, errors = generate_data(False, p_x, p_y, p_z, tot_samples)\n",
    "X_train = syndromes\n",
    "y_train = errors\n",
    "\n",
    "# process data for argmax P(e/s)\n",
    "\n",
    "X_train_unique = np.unique(X_train, axis=0)\n",
    "y_train_unique = np.zeros([X_train_unique.shape[0], y_train.shape[1]])\n",
    "\n",
    "temp_ind = 0\n",
    "for train_sample in X_train_unique:\n",
    "    temp_error_list = y_train[np.all(X_train == train_sample, axis=1)]  \n",
    "    temp_error_list_unique, counts = np.unique(temp_error_list, axis=0, return_counts=True)\n",
    "    y_train_unique[temp_ind] = temp_error_list_unique[counts == max(counts)][0,:].flatten()\n",
    "    temp_ind = temp_ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 1.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 1., 0., 0., 0., 0., 0., 1.]]), array([64, 12]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train[np.all(X_train ==  [1., 0., 1., 0.] , axis=1)], axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_unique[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('testfile.txt','w') \n",
    " \n",
    "file.write(str(a)) \n",
    "file.write('\\n\\n\\n') \n",
    "file.write(str(a)) \n",
    " \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
